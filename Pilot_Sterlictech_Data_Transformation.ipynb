{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YjZ2Paeq6wNL1jX7yd0z8TwhekNNBCzZ",
      "authorship_tag": "ABX9TyNV1JzXaeY7KCqSykf2CqQ1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqpxdfOluV8Z",
        "outputId": "16deb100-249b-4d3c-bcec-c07aaddc099f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 complete.\n",
            "Total selected URLs: 386\n",
            "Processing index entries: 144\n",
            "Errors logged: 0\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/Upwork/david-grass/pilot_folder\")  # project root\n",
        "BUNDLE_MANIFEST_PATH = BASE_DIR / \"inputs\" / \"bundle_manifest.json\"\n",
        "SITEMAP_ANALYSIS_PATH = BASE_DIR / \"inputs\" / \"sitemap_analysis.json\"\n",
        "\n",
        "OUTPUT_PATH = BASE_DIR / \"processing_index.json\"\n",
        "\n",
        "# Page types we NEVER want to process\n",
        "SKIP_PAGE_TYPES = {\n",
        "    \"homepage\",\n",
        "    \"category_landing\",\n",
        "    \"blog\",\n",
        "    \"cms\",\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD INPUT FILES\n",
        "# -----------------------------\n",
        "with open(BUNDLE_MANIFEST_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    bundle_manifest = json.load(f)\n",
        "\n",
        "with open(SITEMAP_ANALYSIS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    sitemap_analysis = json.load(f)\n",
        "\n",
        "selected_urls = set(bundle_manifest.get(\"selected_urls\", []))\n",
        "\n",
        "# -----------------------------\n",
        "# BUILD URL â†’ SITEMAP LOOKUP\n",
        "# -----------------------------\n",
        "sitemap_by_url = {}\n",
        "for row in sitemap_analysis:\n",
        "    url = row.get(\"url\")\n",
        "    if url:\n",
        "        sitemap_by_url[url] = row\n",
        "\n",
        "# -----------------------------\n",
        "# PROCESS SELECTED URLS\n",
        "# -----------------------------\n",
        "processing_index = []\n",
        "errors = []\n",
        "\n",
        "for url in sorted(selected_urls):\n",
        "    sitemap_row = sitemap_by_url.get(url)\n",
        "\n",
        "    if not sitemap_row:\n",
        "        errors.append({\n",
        "            \"url\": url,\n",
        "            \"reason\": \"URL not found in sitemap_analysis.json\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    status = sitemap_row.get(\"status\")\n",
        "    page_type = sitemap_row.get(\"page_type\")\n",
        "\n",
        "    # Skip explicitly marked or unsupported pages\n",
        "    if status == \"skip\":\n",
        "        continue\n",
        "\n",
        "    if page_type in SKIP_PAGE_TYPES:\n",
        "        continue\n",
        "\n",
        "    dir_path = BASE_DIR / sitemap_row.get(\"dir\", \"\")\n",
        "    page_html_path = dir_path / \"page.html\"\n",
        "    tables_json_path = dir_path / \"tables.json\"\n",
        "\n",
        "    record = {\n",
        "        \"source_url\": url,\n",
        "        \"slug\": sitemap_row.get(\"slug\"),\n",
        "        \"page_type\": page_type,\n",
        "        \"status\": status,\n",
        "        \"dir\": str(dir_path),\n",
        "        \"page_html_path\": str(page_html_path),\n",
        "        \"tables_json_path\": str(tables_json_path),\n",
        "        \"has_page_html\": page_html_path.exists(),\n",
        "        \"has_tables_json\": tables_json_path.exists(),\n",
        "    }\n",
        "\n",
        "    # Track missing critical files\n",
        "    if not record[\"has_page_html\"]:\n",
        "        errors.append({\n",
        "            \"url\": url,\n",
        "            \"reason\": \"Missing page.html\",\n",
        "            \"expected_path\": str(page_html_path)\n",
        "        })\n",
        "\n",
        "    processing_index.append(record)\n",
        "\n",
        "# -----------------------------\n",
        "# WRITE OUTPUTS\n",
        "# -----------------------------\n",
        "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(processing_index, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "if errors:\n",
        "    with open(\"processing_index_errors.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(errors, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Step 1 complete.\")\n",
        "print(f\"Total selected URLs: {len(selected_urls)}\")\n",
        "print(f\"Processing index entries: {len(processing_index)}\")\n",
        "print(f\"Errors logged: {len(errors)}\")"
      ]
    }
  ]
}