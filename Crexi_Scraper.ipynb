{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn1OjcNEKJ6B2LFcg8Wc9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/amien-scrapers/blob/main/Crexi_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ufxf3qEuHP_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!pip install xlsxwriter\n",
        "\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from itertools import cycle\n",
        "\n",
        "# get state polygons\n",
        "!wget 'https://github.com/amien1410/scraping-projects/raw/main/sp-big-v3.json'\n",
        "!wget 'https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/socks4.txt'\n",
        "with open('/content/socks4.txt', \"rb\") as f:\n",
        "   json_data = json.load(f)\n",
        "\n",
        "# # opening the CSV file\n",
        "proxies = []\n",
        "with open('/content/socks4.txt', mode ='r') as f:\n",
        "   lines = f.readlines()\n",
        "   for l in lines:\n",
        "         proxies.append(l.strip())\n",
        "\n",
        "def get_polygons(state):\n",
        "  for item in json_data:\n",
        "    if item['state'] == state:\n",
        "      my_item = item\n",
        "      break\n",
        "  else:\n",
        "    return False\n",
        "  return my_item['polygons']\n",
        "\n",
        "def get_properties(name, search_type, filter):\n",
        "  # payload = {\"locations\":[{\"placeId\":\"ChIJSx6SrQ9T2YARed8V_f0hOg0\",\"type\":\"city\",\"city\":city,\"polygons\":[{\"coordinates\":[]},{\"coordinates\":[]},{\"coordinates\":[]},{\"coordinates\":[]}]}],\"count\":1000,\"mlScenario\":\"search-properties\",\"offset\":0,\"userId\":\"$device:1892ba1bdda2059-09edcca6e4277e-7e56547f-13c680-1892ba1bdda2059\",\"sortDirection\":\"Descending\",\"sortOrder\":\"rank\",\"includeUnpriced\":True}\n",
        "  results = []\n",
        "  hasNextPage = True\n",
        "  offset = 0\n",
        "  prox = cycle(proxies)\n",
        "\n",
        "  while hasNextPage == True:\n",
        "    proxy = next(prox)\n",
        "    if search_type == \"State\":\n",
        "      polygons = get_polygons(name)\n",
        "      if polygons == False:\n",
        "        print(\"wrong state!\")\n",
        "        return False\n",
        "      payload = {\n",
        "        \"locations\": [\n",
        "          {\n",
        "            \"placeId\": \"ChIJdf5LHzR_hogR6czIUzU0VV4\",\n",
        "            \"type\": \"stateCode\",\n",
        "            # \"stateCode\": \"AL\",\n",
        "            \"polygons\": polygons\n",
        "          }\n",
        "        ],\n",
        "        \"types\": [filter],\n",
        "        \"count\": 500,\n",
        "        \"mlScenario\": \"search-properties\",\n",
        "        \"offset\": offset,\n",
        "        \"excludeAssetIds\": [],\n",
        "        \"userId\": \"$device:1892b8ff0074068-088509215b1abe-7e56547f-100200-1892b8ff0074068\",\n",
        "        \"sortDirection\": \"Descending\",\n",
        "        \"sortOrder\": \"rank\",\n",
        "        \"includeUnpriced\": True\n",
        "      }\n",
        "    else:\n",
        "      payload = {\n",
        "        \"locations\": [\n",
        "          {\n",
        "            \"placeId\": \"ChIJSx6SrQ9T2YARed8V_f0hOg0\",\n",
        "            \"type\": \"city\",\n",
        "            \"city\": name,\n",
        "            \"polygons\": [\n",
        "              {\n",
        "                \"coordinates\": []\n",
        "              },\n",
        "              {\n",
        "                \"coordinates\": []\n",
        "              },\n",
        "              {\n",
        "                \"coordinates\": []\n",
        "              },\n",
        "              {\n",
        "                \"coordinates\": []\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        ],\n",
        "        \"types\": [filter],\n",
        "        \"count\": 500,\n",
        "        \"mlScenario\": \"search-properties\",\n",
        "        \"offset\": offset,\n",
        "        \"userId\": \"$device:1892ba1bdda2059-09edcca6e4277e-7e56547f-13c680-1892ba1bdda2059\",\n",
        "        \"sortDirection\": \"Descending\",\n",
        "        \"sortOrder\": \"rank\",\n",
        "        \"includeUnpriced\": True\n",
        "      }\n",
        "    url = \"https://api.crexi.com/assets/search\"\n",
        "    r = requests.post(url, json=payload, proxies={'http':'http://'+proxy})\n",
        "    data = r.json()\n",
        "\n",
        "    if 'errors' in data:\n",
        "      print(\"Properties can be shown for you just 1500 properties\")\n",
        "      return results\n",
        "\n",
        "    for i in range(len(data['data'])):\n",
        "      try:\n",
        "        results.append({\n",
        "            \"propertyId\": data['data'][i]['id'],\n",
        "            \"propertyName\": data['data'][i]['name'],\n",
        "            \"url\": data['data'][i]['urlSlug']\n",
        "        })\n",
        "\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    if len(data['data']) < 500:\n",
        "      hasNextPage = False\n",
        "\n",
        "    offset += 500\n",
        "    time.sleep(2)\n",
        "\n",
        "  print(\"Found: \" + str(len(results)) + \" properties.\")\n",
        "  return results\n",
        "\n",
        "\n",
        "async def get_property_info(propertyId):\n",
        "\n",
        "    url = \"https://api.crexi.com/assets/\" + str(propertyId)\n",
        "    print(f\"Property URL: {url}\")\n",
        "    r = requests.get(url)\n",
        "    data = r.json()\n",
        "    # print(data)\n",
        "    details = {k.replace(' ', ''): v for k, v in data[\"details\"].items()}\n",
        "    # print(details)\n",
        "\n",
        "    try:\n",
        "      highlights = data.get('investmentHighlights',\"\")\n",
        "      cleanHighlights = BeautifulSoup(highlights, \"html.parser\").text\n",
        "      marketingDescription = data.get('marketingDescription',\"\")\n",
        "      cleanMarketingDescription = BeautifulSoup(marketingDescription, \"html.parser\").text\n",
        "      askingPrice = data.get(\"askingPrice\", \"\")\n",
        "      property_type = data[\"details\"].get(\"Property Type\", \"\")\n",
        "      subtype = data[\"details\"].get(\"Subtype\", \"\")\n",
        "      investment_type = data[\"details\"].get(\"Investment Type\", \"\")\n",
        "      leaseType = details.get(\"LeaseType\", \"\")\n",
        "      tenantCredit = details.get(\"TenantCredit\", \"\")\n",
        "      tenancy = details.get(\"Tenancy\", \"\")\n",
        "      brandt = data[\"details\"].get(\"Brand/Tenant\", \"\")\n",
        "      lease_tearm = data[\"details\"].get(\"Lease Term\", \"\")\n",
        "      lease_commencement = data[\"details\"].get(\"Lease Commencement\", \"\")\n",
        "      lease_expiration = data[\"details\"].get(\"Lease Expiration\", \"\")\n",
        "      remaining_term = data[\"details\"].get(\"Remaining Term\", \"\")\n",
        "      address = data[\"locations\"][0].get(\"address\", \"\")\n",
        "      city = data[\"locations\"][0].get(\"city\", \"\")\n",
        "      state = data[\"locations\"][0].get(\"state\", {}).get(\"code\", \"\")\n",
        "      zip_code = data[\"locations\"][0].get(\"zip\", \"\")\n",
        "      latitude = data[\"locations\"][0].get(\"latitude\", \"\")\n",
        "      longitude = data[\"locations\"][0].get(\"longitude\", \"\")\n",
        "      square_footage = data[\"details\"].get(\"Square Footage\", \"\")\n",
        "      price_sq_ft = data[\"details\"].get(\"Price/Sq Ft\", \"\")\n",
        "      cap_rate = data[\"details\"].get(\"Cap Rate\", \"\")\n",
        "      occupancy = data[\"details\"].get(\"Occupancy\", \"\")\n",
        "      noi = data[\"details\"].get(\"NOI\", \"\")\n",
        "      year_built = data[\"details\"].get(\"Year Built\", \"\")\n",
        "      permitted_zoning = data[\"details\"].get(\"Permitted Zoning\", \"\")\n",
        "      rent_bumps = data[\"details\"].get(\"Rent Bumps\", \"\")\n",
        "      apn = data[\"details\"].get(\"APN\", \"\")\n",
        "      lease_options = data[\"details\"].get(\"Lease Options\", \"\")\n",
        "      fee_agreement_required = data.get(\"feeAgreementIsRequired\", \"\")\n",
        "      user_can_download_md = data.get(\"userCanDownloadMd\", \"\")\n",
        "      user_executed_ca = data.get(\"userExecutedCA\", \"\")\n",
        "      is_saved_to_boards = data.get(\"isSavedToBoards\", \"\")\n",
        "      ca_principal_info_type = data.get(\"caPrincipalInfoType\", \"\")\n",
        "      is_in_opportunity_zone = data.get(\"isInOpportunityZone\", \"\")\n",
        "      is_note_loan = data.get(\"isNoteLoan\", \"\")\n",
        "      deposit_option = data.get(\"depositOption\", \"\")\n",
        "      broker_plan = data.get(\"brokerPlan\", \"\")\n",
        "      is_sold = data.get(\"isSold\", \"\")\n",
        "      is_paused = data.get(\"isPaused\", \"\")\n",
        "      is_outdated = data.get(\"isOutdated\", \"\")\n",
        "      status = data.get(\"status\", \"\")\n",
        "      id = data.get(\"id\", \"\")\n",
        "      name = data.get(\"name\", \"\")\n",
        "      description = data.get(\"description\", \"\")\n",
        "      thumbnail_url = data.get(\"thumbnailUrl\", \"\")\n",
        "      is_private = data.get(\"isPrivate\", \"\")\n",
        "      url_property = \"https://www.crexi.com/properties/\" + str(id) + \"/\" + data.get(\"urlSlug\", \"\")\n",
        "      is_comp = data.get(\"isComp\", \"\")\n",
        "      is_elite = data.get(\"isElite\", \"\")\n",
        "      is_sell_subject_to = data.get(\"isSellSubjectTo\", \"\")\n",
        "\n",
        "      return {\n",
        "        'isPaid': data[\"isPaid\"],\n",
        "        'investmentHighlights': cleanHighlights,\n",
        "        'marketingDescription': cleanMarketingDescription,\n",
        "        'Asking Price': askingPrice,\n",
        "        'Property Type': property_type,\n",
        "        'Subtype': subtype,\n",
        "        'Investment Type': investment_type,\n",
        "        'Lease Type': leaseType,\n",
        "        'Tenant Credit': tenantCredit,\n",
        "        'Tenancy': tenancy,\n",
        "        'Brand/Tenant': brandt,\n",
        "        'Lease Term': lease_tearm,\n",
        "        'Lease Commencement': lease_commencement,\n",
        "        'Lease Expiration': lease_expiration,\n",
        "        'Remaining Term': remaining_term,\n",
        "        'Square Footage': square_footage,\n",
        "        'Price/Sq Ft': price_sq_ft,\n",
        "        'Cap Rate': cap_rate,\n",
        "        'Occupancy': occupancy,\n",
        "        'NOI': noi,\n",
        "        'Year Built': year_built,\n",
        "        'Permitted Zoning': permitted_zoning,\n",
        "        'Rent Bumps': rent_bumps,\n",
        "        'APN': apn,\n",
        "        'Lease Options': lease_options,\n",
        "        'createdOn': data[\"createdOn\"],\n",
        "        'activatedOn': data[\"activatedOn\"],\n",
        "        'Address': address,\n",
        "        'City': city,\n",
        "        'State': state,\n",
        "        'Zip Code': zip_code,\n",
        "        'Latitude': latitude,\n",
        "        'Longitude': longitude,\n",
        "        'Fee Agreement Required': fee_agreement_required,\n",
        "        'User Can Download MD': user_can_download_md,\n",
        "        'User Executed CA': user_executed_ca,\n",
        "        'Is Saved to Boards': is_saved_to_boards,\n",
        "        'CA Principal Info Type': ca_principal_info_type,\n",
        "        'Is in Opportunity Zone': is_in_opportunity_zone,\n",
        "        'Is Note Loan': is_note_loan,\n",
        "        'Deposit Option': deposit_option,\n",
        "        'Broker Plan': broker_plan,\n",
        "        'Is Sold': is_sold,\n",
        "        'Is Paused': is_paused,\n",
        "        'Is Outdated': is_outdated,\n",
        "        'Status': status,\n",
        "        'ID': id,\n",
        "        'Name': name,\n",
        "        'Description': description,\n",
        "        'Thumbnail URL': thumbnail_url,\n",
        "        'Is Private': is_private,\n",
        "        'URL Property': url_property,\n",
        "        'Is Comp': is_comp,\n",
        "        'Is Elite': is_elite,\n",
        "        'Is Sell Subject To': is_sell_subject_to\n",
        "    }\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "\n",
        "async def main(name, type, filter):\n",
        "  results = []\n",
        "  properties = get_properties(name, type, filter)\n",
        "  for i in range(len(properties)):\n",
        "    print(f\"Task: {i}\")\n",
        "    try:\n",
        "      print(f\"Property ID: {properties[i]['propertyId']}\")\n",
        "      data = await get_property_info(properties[i][\"propertyId\"])\n",
        "      results.append(data)\n",
        "    except:\n",
        "      continue\n",
        "  results = [x for x in results if x is not None]\n",
        "  df = pd.DataFrame(results)\n",
        "  df.to_excel(\"Florida-Crexi.xlsx\", engine='xlsxwriter')\n",
        "  files.download(\"Florida-Crexi.xlsx\")\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await main(\"Florida\", \"State\", \"Multifamily\")\n",
        "# await main(\"San Diego\", \"City\", \"Retail\")\n",
        "# get_properties(\"Arizona\", \"State\", \"Retail\")"
      ],
      "metadata": {
        "id": "X0bkGGknfow0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Revised\n",
        "!pip install xlsxwriter\n",
        "\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# get state polygons\n",
        "!wget 'https://github.com/amien1410/scraping-projects/raw/main/sp-big-v3.json'\n",
        "\n",
        "with open('sp-big-v3.json', 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "\n",
        "def get_polygons(state):\n",
        "  for item in json_data:\n",
        "    if item['state'] == state:\n",
        "      return item['polygons']\n",
        "  return False\n",
        "\n",
        "def get_properties(name, search_type, filter):\n",
        "  results = []\n",
        "  hasNextPage = True\n",
        "  offset = 0\n",
        "\n",
        "  while hasNextPage:\n",
        "    if search_type == \"State\":\n",
        "      polygons = get_polygons(name)\n",
        "      if polygons is False:\n",
        "        print(\"Wrong state!\")\n",
        "        return False\n",
        "      payload = {\n",
        "        \"locations\": [\n",
        "          {\n",
        "            \"placeId\": \"ChIJdf5LHzR_hogR6czIUzU0VV4\",\n",
        "            \"type\": \"stateCode\",\n",
        "            \"polygons\": polygons\n",
        "          }\n",
        "        ],\n",
        "        \"types\": [filter],\n",
        "        \"count\": 500,\n",
        "        \"mlScenario\": \"search-properties\",\n",
        "        \"offset\": offset,\n",
        "        \"excludeAssetIds\": [],\n",
        "        \"userId\": \"$device:1892b8ff0074068-088509215b1abe-7e56547f-100200-1892b8ff0074068\",\n",
        "        \"sortDirection\": \"Descending\",\n",
        "        \"sortOrder\": \"rank\",\n",
        "        \"includeUnpriced\": True\n",
        "      }\n",
        "    else:\n",
        "      payload = {\n",
        "        \"locations\": [\n",
        "          {\n",
        "            \"placeId\": \"ChIJSx6SrQ9T2YARed8V_f0hOg0\",\n",
        "            \"type\": \"city\",\n",
        "            \"city\": name,\n",
        "            \"polygons\": [{\"coordinates\": []}] * 4\n",
        "          }\n",
        "        ],\n",
        "        \"types\": [filter],\n",
        "        \"count\": 500,\n",
        "        \"mlScenario\": \"search-properties\",\n",
        "        \"offset\": offset,\n",
        "        \"userId\": \"$device:1892ba1bdda2059-09edcca6e4277e-7e56547f-13c680-1892ba1bdda2059\",\n",
        "        \"sortDirection\": \"Descending\",\n",
        "        \"sortOrder\": \"rank\",\n",
        "        \"includeUnpriced\": True\n",
        "      }\n",
        "\n",
        "    url = \"https://api.crexi.com/assets/search\"\n",
        "    try:\n",
        "      r = requests.post(url, json=payload)\n",
        "      data = r.json()\n",
        "    except Exception as e:\n",
        "      print(\"Request failed:\", e)\n",
        "      return results\n",
        "\n",
        "    if 'errors' in data:\n",
        "      print(\"Properties can be shown for you just 1500 properties\")\n",
        "      return results\n",
        "\n",
        "    for item in data.get('data', []):\n",
        "      try:\n",
        "        results.append({\n",
        "            \"propertyId\": item['id'],\n",
        "            \"propertyName\": item['name'],\n",
        "            \"url\": item['urlSlug']\n",
        "        })\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    if len(data['data']) < 500:\n",
        "      hasNextPage = False\n",
        "\n",
        "    offset += 500\n",
        "    time.sleep(2)\n",
        "\n",
        "  print(\"Found: \" + str(len(results)) + \" properties.\")\n",
        "  return results\n",
        "\n",
        "\n",
        "async def get_property_info(propertyId):\n",
        "    url = \"https://api.crexi.com/assets/\" + str(propertyId)\n",
        "    print(f\"Property URL: {url}\")\n",
        "    r = requests.get(url)\n",
        "    data = r.json()\n",
        "    details = {k.replace(' ', ''): v for k, v in data.get(\"details\", {}).items()}\n",
        "\n",
        "    try:\n",
        "      highlights = BeautifulSoup(data.get('investmentHighlights', \"\"), \"html.parser\").text\n",
        "      marketingDescription = BeautifulSoup(data.get('marketingDescription', \"\"), \"html.parser\").text\n",
        "      locations = data.get(\"locations\", [{}])\n",
        "      state_code = locations[0].get(\"state\", {}).get(\"code\", \"\")\n",
        "\n",
        "      return {\n",
        "        'isPaid': data.get(\"isPaid\"),\n",
        "        'investmentHighlights': highlights,\n",
        "        'marketingDescription': marketingDescription,\n",
        "        'Asking Price': data.get(\"askingPrice\", \"\"),\n",
        "        'Property Type': details.get(\"PropertyType\", \"\"),\n",
        "        'Subtype': details.get(\"Subtype\", \"\"),\n",
        "        'Investment Type': details.get(\"InvestmentType\", \"\"),\n",
        "        'Lease Type': details.get(\"LeaseType\", \"\"),\n",
        "        'Tenant Credit': details.get(\"TenantCredit\", \"\"),\n",
        "        'Tenancy': details.get(\"Tenancy\", \"\"),\n",
        "        'Brand/Tenant': details.get(\"Brand/Tenant\", \"\"),\n",
        "        'Lease Term': details.get(\"LeaseTerm\", \"\"),\n",
        "        'Lease Commencement': details.get(\"LeaseCommencement\", \"\"),\n",
        "        'Lease Expiration': details.get(\"LeaseExpiration\", \"\"),\n",
        "        'Remaining Term': details.get(\"RemainingTerm\", \"\"),\n",
        "        'Square Footage': details.get(\"SquareFootage\", \"\"),\n",
        "        'Price/Sq Ft': details.get(\"Price/SqFt\", \"\"),\n",
        "        'Cap Rate': details.get(\"CapRate\", \"\"),\n",
        "        'Occupancy': details.get(\"Occupancy\", \"\"),\n",
        "        'NOI': details.get(\"NOI\", \"\"),\n",
        "        'Year Built': details.get(\"YearBuilt\", \"\"),\n",
        "        'Permitted Zoning': details.get(\"PermittedZoning\", \"\"),\n",
        "        'Rent Bumps': details.get(\"RentBumps\", \"\"),\n",
        "        'APN': details.get(\"APN\", \"\"),\n",
        "        'Lease Options': details.get(\"LeaseOptions\", \"\"),\n",
        "        'Address': locations[0].get(\"address\", \"\"),\n",
        "        'City': locations[0].get(\"city\", \"\"),\n",
        "        'State': state_code,\n",
        "        'Zip Code': locations[0].get(\"zip\", \"\"),\n",
        "        'Latitude': locations[0].get(\"latitude\", \"\"),\n",
        "        'Longitude': locations[0].get(\"longitude\", \"\"),\n",
        "        'Status': data.get(\"status\", \"\"),\n",
        "        'ID': data.get(\"id\", \"\"),\n",
        "        'Name': data.get(\"name\", \"\"),\n",
        "        'Description': data.get(\"description\", \"\"),\n",
        "        'URL Property': \"https://www.crexi.com/properties/\" + str(data.get(\"id\", \"\")) + \"/\" + data.get(\"urlSlug\", \"\")\n",
        "      }\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error parsing property {propertyId}: {e}\")\n",
        "      return None\n",
        "\n",
        "\n",
        "async def main(name, type, filter):\n",
        "  results = []\n",
        "  properties = get_properties(name, type, filter)\n",
        "  for i, prop in enumerate(properties):\n",
        "    print(f\"Task: {i}\")\n",
        "    try:\n",
        "      data = await get_property_info(prop[\"propertyId\"])\n",
        "      if data:\n",
        "        results.append(data)\n",
        "    except Exception as e:\n",
        "      print(f\"Error fetching property info: {e}\")\n",
        "      continue\n",
        "  df = pd.DataFrame(results)\n",
        "  df.to_excel(\"Crexi-Properties.xlsx\", engine='xlsxwriter')\n",
        "  files.download(\"Crexi-Properties.xlsx\")\n",
        "  return df"
      ],
      "metadata": {
        "id": "64wIRlzUrtWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}