{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJcqYzQUXT+KgIh5IOrG2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/amien-scrapers/blob/main/Trustpilot_Reviews_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Modules and Functions (Click play button below)"
      ],
      "metadata": {
        "id": "8cxW-CLoCJS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GsaSks5NCHk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Initiate headers\n",
        "headers = {\n",
        "    \"Host\": \"www.trustpilot.com\",\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:126.0) Gecko/20100101 Firefox/126.0\",\n",
        "    \"Accept\": \"*/*\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
        "    \"Referer\": \"https://www.trustpilot.com/review/prodigyfinance.com\",\n",
        "    \"x-nextjs-data\": \"1\",\n",
        "    \"Connection\": \"keep-alive\",\n",
        "    \"Cookie\": \"OptanonConsent=isGpcEnabled=0&datestamp=Sat+May+18+2024+08%3A52%3A55+GMT%2B0800+(China+Standard+Time)&version=6.28.0&isIABGlobal=false&hosts=&consentId=db739580-2c05-49ff-a98a-516a3dbcbef9&interactionCount=2&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0003%3A1%2CC0004%3A1&AwaitingReconsent=false; TP.uuid=2c74dd4f-b48b-4218-90da-bcfb1aa1f011; _hjSessionUser_391767=eyJpZCI6IjgzOGQwNTUxLTIzY2QtNTExOS1iY2QyLTFhNGE1NzZjY2UwNSIsImNyZWF0ZWQiOjE3MTU5OTMxNzc5MTAsImV4aXN0aW5nIjp0cnVlfQ==; _hjSession_391767=eyJpZCI6IjM4MmVkN2M5LTI2YTEtNGM1Mi1iMmI5LTY0ZjJmNmNiNGU2YyIsImMiOjE3MTU5OTMxNzc5MTIsInMiOjEsInIiOjEsInNiIjowLCJzciI6MCwic2UiOjAsImZzIjoxLCJzcCI6MX0=; ajs_anonymous_id=7ac94ec7-630d-4359-9c7a-e8c16de4266f; amplitude_idundefinedtrustpilot.com=eyJvcHRPdXQiOmZhbHNlLCJzZXNzaW9uSWQiOm51bGwsImxhc3RFdmVudFRpbWUiOm51bGwsImV2ZW50SWQiOjAsImlkZW50aWZ5SWQiOjAsInNlcXVlbmNlTnVtYmVyIjowfQ==; amplitude_id_67f7b7e6c8cb1b558b0c5bda2f747b07trustpilot.com=eyJkZXZpY2VJZCI6IjM0OGFkZDNkLTc5N2UtNDg2Zi1iZTg5LWI3NDhkNjI0MTU2NlIiLCJ1c2VySWQiOm51bGwsIm9wdE91dCI6ZmFsc2UsInNlc3Npb25JZCI6MTcxNTk5MzE4Njc3MCwibGFzdEV2ZW50VGltZSI6MTcxNTk5MzU2ODA0OCwiZXZlbnRJZCI6NSwiaWRlbnRpZnlJZCI6MCwic2VxdWVuY2VOdW1iZXIiOjV9; _gcl_au=1.1.1883098336.1715993193; _hjHasCachedUserAttributes=true; _tt_enable_cookie=1; _ttp=J87slJZtgAwRD7KZmgwdj1bX5NN; _ga_11HBWMC274=GS1.1.1715993199.1.1.1715993569.34.0.0; _ga=GA1.1.1321321732.1715993200; _hjUserAttributesHash=e924cae0540e45e3eeaece5bbca58716; OptanonAlertBoxClosed=2024-05-18T00:52:55.568Z\",\n",
        "    \"Sec-Fetch-Dest\": \"empty\",\n",
        "    \"Sec-Fetch-Mode\": \"cors\",\n",
        "    \"Sec-Fetch-Site\": \"same-origin\",\n",
        "    \"Priority\": \"u=1\",\n",
        "    \"TE\": \"trailers\"\n",
        "}\n",
        "\n",
        "# Function to validate the URL\n",
        "def is_valid_url(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    return parsed_url.scheme == \"https\" and parsed_url.netloc == \"www.trustpilot.com\" and parsed_url.path.startswith(\"/review/\")\n",
        "\n",
        "# Function to get all reviews\n",
        "def scrapeReviews(baseUrl):\n",
        "    page = 1\n",
        "    all_reviews = []\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Construct URL with page parameter (except for first page)\n",
        "            url = baseUrl if page == 1 else f\"{baseUrl}?page={page}\"\n",
        "            print(f\"Scraping reviews from: {url}\")\n",
        "\n",
        "            # Get reviews for this page\n",
        "            res = requests.get(url, headers=headers)\n",
        "            res.raise_for_status()\n",
        "            soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "            # Find the script tag with the specific id and type\n",
        "            script_tag = soup.find('script', {'id': '__NEXT_DATA__', 'type': 'application/json'})\n",
        "\n",
        "            # Extract the JSON string inside the script tag and convert it to a Python dictionary\n",
        "            if script_tag:\n",
        "                json_string = script_tag.string.strip()\n",
        "                json_data = json.loads(json_string)\n",
        "                reviews = json_data.get('props', {}).get('pageProps', {}).get('reviews', [])\n",
        "\n",
        "            # Check if there are any reviews on this page\n",
        "            if not reviews:\n",
        "                break\n",
        "\n",
        "            # Add reviews to the list\n",
        "            print(f\"Total comments on this page: {len(reviews)}\")\n",
        "            all_reviews.extend(reviews)\n",
        "\n",
        "            # Check if there are less than 20 reviews on this page\n",
        "            if len(reviews) < 20:\n",
        "                break\n",
        "\n",
        "            # Increment page number\n",
        "            page += 1\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error occurred: {e}. Retrying in 5 seconds...\")\n",
        "            time.sleep(5)\n",
        "            continue  # Retry from the last page\n",
        "\n",
        "    return all_reviews\n",
        "\n",
        "# Function to convert url into filename\n",
        "def getFilename(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    filename = parsed_url.path.split('/')[-1]\n",
        "    return filename\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    result = []\n",
        "    url = input(\"Enter your Trustpilot url here: \")\n",
        "\n",
        "    while not is_valid_url(url):\n",
        "        print(\"Invalid URL. The URL must be in the format: https://www.trustpilot.com/review/[company]\")\n",
        "        url = input(\"Enter your Trustpilot url here: \")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            allReviews = scrapeReviews(url)\n",
        "            break\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Network error: {e}. Please check your internet connection or the URL and try again.\")\n",
        "            url = input(\"Enter your Trustpilot url here: \")\n",
        "\n",
        "    filename = getFilename(url)\n",
        "    for data in allReviews:\n",
        "        result.append({\n",
        "            \"reviewId\": data[\"id\"],\n",
        "            \"title\": data[\"title\"],\n",
        "            \"text\": data[\"text\"],\n",
        "            \"rating\": data[\"rating\"],\n",
        "            \"isVerified\": data[\"labels\"][\"verification\"][\"isVerified\"],\n",
        "            \"likes\": data[\"likes\"],\n",
        "            \"publishedDate\": data[\"dates\"][\"publishedDate\"],\n",
        "            \"consumer name\": data[\"consumer\"][\"displayName\"],\n",
        "            \"countryCode\": data[\"consumer\"][\"countryCode\"],\n",
        "            \"reply\": data[\"reply\"][\"message\"] if data[\"reply\"] else None\n",
        "        })\n",
        "    df = pd.DataFrame(result)\n",
        "    df.to_excel(f\"{filename}.xlsx\")\n",
        "    # files.download(f\"{filename}.xlsx\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run The Function (Click play button below), Insert Your Url into the input field, Wait until it finished and download the result automatically (Or you can download manually the file from the left panel)"
      ],
      "metadata": {
        "id": "YFzyJh42CVeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Click the play button on the left to rerun the script https://www.trustpilot.com/review/prodigyfinance.com\n",
        "main()"
      ],
      "metadata": {
        "id": "up3oyvPSy0yv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}