{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJtOUWEB7iVON3DqBNqS8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amien1410/amien-scrapers/blob/main/Zyte_Proxy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCa85SuQZA2g",
        "outputId": "a7ef97cb-ab60-4eb5-89d4-fa4ccd8ab2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping https://lista.mercadolivre.com.br/ps5 via Zyte API...\n",
            "❌ API Error: 403 {\"type\":\"/auth/account-suspended\",\"title\":\"Account Suspended\",\"status\":403,\"detail\":\"Your account has been suspended. Check your Zyte API subscription details at https://app.zyte.com/o/settings/billing-subscriptions for more information. If you have reached your spending limit, increasing your spending limit will immediately lift your account suspension.\"}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': '/auth/account-suspended',\n",
              " 'title': 'Account Suspended',\n",
              " 'status': 403,\n",
              " 'detail': 'Your account has been suspended. Check your Zyte API subscription details at https://app.zyte.com/o/settings/billing-subscriptions for more information. If you have reached your spending limit, increasing your spending limit will immediately lift your account suspension.'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# @title Modules\n",
        "# 205267c080284f458826d6234c7d8b71\n",
        "# 13d7125cf0fe490d8e57ed9ad143140c\n",
        "# 8f46c21a7b4246049c19a0bde260870b\n",
        "\n",
        "from base64 import b64decode\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "ZYTE_API_KEY = \"d17ad62a208846d0a684318c7c7cc6cc\"\n",
        "TARGET_URL = \"https://lista.mercadolivre.com.br/ps5\"\n",
        "\n",
        "# === SEND REQUEST TO ZYTE API ===\n",
        "print(f\"Scraping {TARGET_URL} via Zyte API...\")\n",
        "\n",
        "response = requests.post(\n",
        "    \"https://api.zyte.com/v1/extract\",\n",
        "    auth=(ZYTE_API_KEY, \"\"),\n",
        "    json={\n",
        "        \"url\": TARGET_URL,\n",
        "        \"httpResponseBody\": True,\n",
        "        \"followRedirect\": True\n",
        "    },\n",
        ")\n",
        "\n",
        "# === CHECK RESPONSE ===\n",
        "if response.status_code != 200:\n",
        "    print(\"❌ API Error:\", response.status_code, response.text)\n",
        "    exit()\n",
        "\n",
        "data = response.json()\n",
        "data\n",
        "\n",
        "# # === DECODE HTML CONTENT ===\n",
        "# html_bytes = b64decode(data[\"httpResponseBody\"])\n",
        "# html_text = html_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "# # === PARSE WITH BEAUTIFULSOUP ===\n",
        "# soup = BeautifulSoup(html_text, \"html.parser\")\n",
        "\n",
        "# # Example extraction: title and product listings\n",
        "# page_title = soup.title.string if soup.title else \"No title found\"\n",
        "# product_titles = [item.get_text(strip=True)\n",
        "#                   for item in soup.select(\"h2.ui-search-item__title\")]\n",
        "\n",
        "# print(f\"✅ Page title: {page_title}\")\n",
        "# print(f\"✅ Found {len(product_titles)} product listings.\")\n",
        "\n",
        "# # Print first few results\n",
        "# for i, title in enumerate(product_titles[:5], start=1):\n",
        "#     print(f\"{i}. {title}\")\n",
        "\n",
        "# # Optional: save to local file for inspection\n",
        "# with open(\"mercadolivre_ps5.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     f.write(html_text)\n",
        "#     print(\"\\n💾 Saved HTML to mercadolivre_ps5.html\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "# === CONFIGURATION ===\n",
        "ZYTE_API_KEY = \"91ae5e88754f4ddb843724420c64eb9b\"\n",
        "TARGET_URL = \"https://lista.mercadolivre.com.br/ps5\"\n",
        "\n",
        "response = requests.post(\n",
        "    \"https://api.zyte.com/v1/extract\",\n",
        "    auth=(ZYTE_API_KEY, \"\"),\n",
        "    json={\n",
        "        \"url\": TARGET_URL,\n",
        "        \"httpResponseBody\": True,\n",
        "        \"followRedirect\": True\n",
        "    },\n",
        ")\n",
        "\n",
        "# === CHECK RESPONSE ===\n",
        "if response.status_code != 200:\n",
        "    print(\"❌ API Error:\", response.status_code, response.text)\n",
        "    exit()\n",
        "\n",
        "data = response.json()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZPQPOguBKOw",
        "outputId": "1518cfeb-4683-4385-da15-c810838e6863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ API Error: 403 {\"type\":\"/auth/account-suspended\",\"title\":\"Account Suspended\",\"status\":403,\"detail\":\"Your account has been suspended. Check your Zyte API subscription details at https://app.zyte.com/o/settings/billing-subscriptions for more information. If you have reached your spending limit, increasing your spending limit will immediately lift your account suspension.\"}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': '/auth/account-suspended',\n",
              " 'title': 'Account Suspended',\n",
              " 'status': 403,\n",
              " 'detail': 'Your account has been suspended. Check your Zyte API subscription details at https://app.zyte.com/o/settings/billing-subscriptions for more information. If you have reached your spending limit, increasing your spending limit will immediately lift your account suspension.'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0d5a7e42-3d3d-4c04-a66f-25792694a20f\n",
        "# dd65f504-cb80-4fc1-ab48-49b5d88606c0\n",
        "# 421c1b6c-c329-4935-8536-733a209e04f1\n",
        "# 6b98e85e-ad38-466b-806b-7c8511be9d5e\n",
        "# fba52e3f-8ad2-4af3-a04c-e2f567f1fe8e\n",
        "# daea12f2-c861-4373-b3da-47c01582e74f\n",
        "# c11dcaf1-3e62-41b7-a870-d1522e60e6d5\n",
        "# 114f98df-1065-4775-973c-c74a702f8bbb\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "SCRAPEOPS_API_KEY = \"114f98df-1065-4775-973c-c74a702f8bbb\"\n",
        "TARGET_URL = \"https://books.toscrape.com/\"\n",
        "SCRAPEOPS_ENDPOINT = \"https://proxy.scrapeops.io/v1/\"\n",
        "\n",
        "# === BUILD REQUEST PARAMETERS ===\n",
        "params = {\n",
        "    \"api_key\": SCRAPEOPS_API_KEY,\n",
        "    \"url\": TARGET_URL,\n",
        "    # Optional parameters:\n",
        "    # \"country\": \"us\",\n",
        "    # \"render_js\": \"true\",\n",
        "    # \"residential\": \"true\",\n",
        "    # \"premium_proxy\": \"true\",\n",
        "}\n",
        "\n",
        "print(f\"Scraping {TARGET_URL} through ScrapeOps proxy...\")\n",
        "\n",
        "# === SEND REQUEST ===\n",
        "response = requests.get(SCRAPEOPS_ENDPOINT, params=params)\n",
        "\n",
        "if response.status_code != 200:\n",
        "    print(\"❌ Error:\", response.status_code, response.text)\n",
        "    exit()\n",
        "\n",
        "# === PARSE HTML USING BEAUTIFULSOUP ===\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Example extraction: titles of books\n",
        "titles = [h3.get_text(strip=True) for h3 in soup.select(\"h3 > a\")]\n",
        "\n",
        "print(f\"✅ Found {len(titles)} book titles:\")\n",
        "for i, title in enumerate(titles[:10], start=1):\n",
        "    print(f\"{i}. {title}\")\n",
        "\n",
        "# === OPTIONAL: SAVE HTML TO FILE ===\n",
        "with open(\"books_scraped.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response.text)\n",
        "    print(\"\\n💾 Saved HTML to books_scraped.html\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heJNJycPInxk",
        "outputId": "d181c78c-0a27-4cf7-bfa5-a7936b3be2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping https://books.toscrape.com/ through ScrapeOps proxy...\n",
            "✅ Found 20 book titles:\n",
            "1. A Light in the ...\n",
            "2. Tipping the Velvet\n",
            "3. Soumission\n",
            "4. Sharp Objects\n",
            "5. Sapiens: A Brief History ...\n",
            "6. The Requiem Red\n",
            "7. The Dirty Little Secrets ...\n",
            "8. The Coming Woman: A ...\n",
            "9. The Boys in the ...\n",
            "10. The Black Maria\n",
            "\n",
            "💾 Saved HTML to books_scraped.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ee6c218713741ace3bc734e641275d92\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "SCRAPERAPI_KEY = \"ee6c218713741ace3bc734e641275d92\"\n",
        "TARGET_URL = \"https://books.toscrape.com/\"\n",
        "SCRAPERAPI_ENDPOINT = \"http://api.scraperapi.com\"\n",
        "\n",
        "# === BUILD REQUEST PARAMETERS ===\n",
        "params = {\n",
        "    \"api_key\": SCRAPERAPI_KEY,\n",
        "    \"url\": TARGET_URL,\n",
        "    \"render\": \"true\",          # Enable JS rendering (optional)\n",
        "    # \"country_code\": \"us\",    # Optional geo-targeting\n",
        "    # \"session_number\": \"1\",   # Optional sticky session\n",
        "}\n",
        "\n",
        "print(f\"Scraping {TARGET_URL} via ScraperAPI...\")\n",
        "\n",
        "# === SEND REQUEST ===\n",
        "response = requests.get(SCRAPERAPI_ENDPOINT, params=params)\n",
        "\n",
        "# === HANDLE RESPONSE ===\n",
        "if response.status_code != 200:\n",
        "    print(\"❌ Error:\", response.status_code, response.text)\n",
        "    exit()\n",
        "\n",
        "# === PARSE HTML WITH BEAUTIFULSOUP ===\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Example extraction: Book titles\n",
        "soup\n"
      ],
      "metadata": {
        "id": "JyorivcWI3zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "SCRAPINGBEE_API_KEY = \"M977YHXCMPJJ569DSB0B8KSKL9NRU2O2327MIDT55785T8LS9TJGDW4GFMCMOZNRVN3GPSXF0Y6DGC32\"\n",
        "TARGET_URL = \"https://books.toscrape.com/\"\n",
        "SCRAPINGBEE_ENDPOINT = \"https://app.scrapingbee.com/api/v1/\"\n",
        "\n",
        "# === BUILD REQUEST PARAMETERS ===\n",
        "params = {\n",
        "    \"api_key\": SCRAPINGBEE_API_KEY,\n",
        "    \"url\": TARGET_URL,\n",
        "    \"render_js\": \"false\",  # set to \"true\" if page requires JavaScript rendering\n",
        "    # Optional params:\n",
        "    # \"country_code\": \"us\",\n",
        "    # \"premium_proxy\": \"true\",\n",
        "    # \"block_ads\": \"true\",\n",
        "    # \"wait_for\": \"h3\",     # wait for selector\n",
        "}\n",
        "\n",
        "print(f\"Scraping {TARGET_URL} via ScrapingBee...\")\n",
        "\n",
        "# === SEND REQUEST ===\n",
        "response = requests.get(SCRAPINGBEE_ENDPOINT, params=params)\n",
        "\n",
        "if response.status_code != 200:\n",
        "    print(\"❌ Error:\", response.status_code, response.text)\n",
        "    exit()\n",
        "\n",
        "# === PARSE HTML WITH BEAUTIFULSOUP ===\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Example extraction: book titles\n",
        "titles = [a.get_text(strip=True) for a in soup.select(\"h3 > a\")]\n",
        "\n",
        "print(f\"✅ Found {len(titles)} book titles:\")\n",
        "for i, title in enumerate(titles[:10], start=1):\n",
        "    print(f\"{i}. {title}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX72alhTYha6",
        "outputId": "f8c9f50f-cc3c-4667-9ee1-985d3dd125bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping https://books.toscrape.com/ via ScrapingBee...\n",
            "❌ Error: 401 {\"message\":\"Monthly API calls limit reached: 1000\"}\n",
            "\n",
            "✅ Found 0 book titles:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from base64 import b64decode\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "OXYLABS_USERNAME = \"rhemanth\"   # e.g., customer-username\n",
        "OXYLABS_PASSWORD = \"q8yxYbMmuY\"\n",
        "TARGET_URL = \"https://books.toscrape.com/\"\n",
        "OXYLABS_ENDPOINT = \"https://realtime.oxylabs.io/v1/queries\"\n",
        "\n",
        "# === BUILD REQUEST PAYLOAD ===\n",
        "payload = {\n",
        "    \"source\": \"universal\",  # generic scraping mode\n",
        "    \"url\": TARGET_URL,\n",
        "    \"geo_location\": \"United States\",  # optional\n",
        "    \"parse\": False,  # set True to use Oxylabs’ structured parser\n",
        "}\n",
        "\n",
        "print(f\"Scraping {TARGET_URL} via Oxylabs API...\")\n",
        "\n",
        "# === SEND REQUEST ===\n",
        "response = requests.post(\n",
        "    OXYLABS_ENDPOINT,\n",
        "    auth=(OXYLABS_USERNAME, OXYLABS_PASSWORD),\n",
        "    json=payload,\n",
        ")\n",
        "\n",
        "if response.status_code != 200:\n",
        "    print(\"❌ Error:\", response.status_code, response.text)\n",
        "    exit()\n",
        "\n",
        "data = response.json()\n",
        "\n",
        "# === DECODE BASE64 HTML CONTENT ===\n",
        "html_bytes = b64decode(data[\"results\"][0][\"content\"])\n",
        "html_text = html_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "# === PARSE HTML WITH BEAUTIFULSOUP ===\n",
        "soup = BeautifulSoup(html_text, \"html.parser\")\n",
        "\n",
        "# Example extraction: book titles\n",
        "titles = [a.get_text(strip=True) for a in soup.select(\"h3 > a\")]\n",
        "\n",
        "print(f\"✅ Found {len(titles)} book titles:\")\n",
        "for i, title in enumerate(titles[:10], start=1):\n",
        "    print(f\"{i}. {title}\")\n",
        "\n",
        "# === OPTIONAL: SAVE HTML LOCALLY ===\n",
        "with open(\"books_oxylabs.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_text)\n",
        "    print(\"\\n💾 Saved HTML to books_oxylabs.html\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "nBKgomhTeu5s",
        "outputId": "4f6a12ca-04b4-4c65-8ef6-0ac958d2739a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping https://books.toscrape.com/ via Oxylabs API...\n",
            "❌ Error: 401 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/simplejson/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, allow_nan, **kw)\u001b[0m\n\u001b[1;32m    513\u001b[0m             and not use_decimal and not allow_nan and not kw):\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-604570994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# === DECODE BASE64 HTML CONTENT ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Zenrows Testing\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "TARGET_URL = \"https://books.toscrape.com/\"\n",
        "ZENROWS_ENDPOINT = \"https://api.zenrows.com/v1/\"\n",
        "\n",
        "def zenrows(api_key):\n",
        "    # === BUILD REQUEST PARAMETERS ===\n",
        "    params = {\n",
        "        \"url\": TARGET_URL,\n",
        "        \"apikey\": api_key,\n",
        "        \"js_render\": \"true\"\n",
        "    }\n",
        "\n",
        "    print(f\"Scraping {TARGET_URL} via ZenRows API...\")\n",
        "\n",
        "    # === SEND REQUEST ===\n",
        "    response = requests.get(ZENROWS_ENDPOINT, params=params)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"❌ Error using this {api_key}:\", response.status_code, response.text)\n",
        "        exit()\n",
        "\n",
        "    # === PARSE HTML WITH BEAUTIFULSOUP ===\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Example extraction: book titles\n",
        "    titles = [a.get_text(strip=True) for a in soup.select(\"h3 > a\")]\n",
        "\n",
        "    print(f\"✅ Found {len(titles)} book titles:\")\n",
        "    for i, title in enumerate(titles[:10], start=1):\n",
        "        print(f\"{i}. {title}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N5YYkrCWvyx_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "\n",
        "zenrows(\"813dcf383caedb54fe88f33a4686420821113c5f\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-KyE7NTwfCz",
        "outputId": "db2fc47d-65ce-45fa-ded9-b1b5db68fe77"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping https://books.toscrape.com/ via ZenRows API...\n",
            "❌ Error using this 813dcf383caedb54fe88f33a4686420821113c5f: 402 {\"code\":\"AUTH005\",\"detail\":\"This account has reached its validity period. Purchase a new subscription to continue using the service.\",\"instance\":\"/v1\",\"status\":402,\"title\":\"Account is not longer valid (AUTH005)\",\"type\":\"https://docs.zenrows.com/api-error-codes#AUTH005\"}\n",
            "✅ Found 0 book titles:\n"
          ]
        }
      ]
    }
  ]
}