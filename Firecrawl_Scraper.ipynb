{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17d1lg-iScN687QbhzNBuJSaPACNlI0m_",
      "authorship_tag": "ABX9TyO50v5n1xTjLQcCj4NzFMZb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "# ===============================\n",
        "# 1. ARRAY OF FIRECRAWL API KEYS\n",
        "# ===============================\n",
        "FIRECRAWL_KEYS = [\n",
        "\n",
        "]\n",
        "\n",
        "# ====================\n",
        "# 2. ARRAY OF URLS\n",
        "# ====================\n",
        "URLS = [\n",
        "    \"https://stgeorgembc.com.au/\",\n",
        "    \"https://stgeorgembc.com.au/about-us/\",\n",
        "    \"https://stgeorgembc.com.au/clubgrants-2022/\",\n",
        "    \"https://stgeorgembc.com.au/club-history/\",\n",
        "    \"https://stgeorgembc.com.au/trading-hours/\",\n",
        "    \"https://stgeorgembc.com.au/gallery/\",\n",
        "    \"https://stgeorgembc.com.au/courtesy-bus/\",\n",
        "    \"https://stgeorgembc.com.au/frequently-asked-questions/\",\n",
        "    \"https://stgeorgembc.com.au/we-care/\",\n",
        "    \"https://stgeorgembc.com.au/latest-news/\",\n",
        "    \"https://stgeorgembc.com.au/venue-safety-plan/\",\n",
        "    \"https://stgeorgembc.com.au/join-our-team/\",\n",
        "    \"https://stgeorgembc.com.au/our-fantastic-staff/\",\n",
        "    \"https://stgeorgembc.com.au/annual-report/\",\n",
        "    \"https://stgeorgembc.com.au/membership-reminder/\",\n",
        "    \"https://stgeorgembc.com.au/dress-regulations/\",\n",
        "    \"https://stgeorgembc.com.au/marina/\",\n",
        "    \"https://stgeorgembc.com.au/marina/marina-berthing/\",\n",
        "    \"https://stgeorgembc.com.au/environmental/\",\n",
        "    \"https://stgeorgembc.com.au/mooring-detail-search/\",\n",
        "    \"https://stgeorgembc.com.au/boat-ramp/\",\n",
        "    \"https://stgeorgembc.com.au/boat-hire/\",\n",
        "    \"https://stgeorgembc.com.au/restaurant-menus/\",\n",
        "    \"https://stgeorgembc.com.au/meet-our-chefs/\",\n",
        "    \"https://stgeorgembc.com.au/wp-content/uploads/2023/10/BayBreeze-Cafe-231017.pdf\",\n",
        "    \"https://stgeorgembc.com.au/wp-content/uploads/2023/05/Pizza-.pdf\",\n",
        "    \"https://stgeorgembc.com.au/#\",\n",
        "    \"https://stgeorgembc.com.au/whats-on/entertainment/\",\n",
        "    \"https://stgeorgembc.com.au/sub-clubs/\",\n",
        "    \"https://stgeorgembc.com.au/contact/\",\n",
        "    \"https://stgeorgembc.com.au/whats-on/\",\n",
        "    \"https://stgeorgembc.com.au/whats-on/promotions-and-raffles/\",\n",
        "    \"https://stgeorgembc.com.au/new-badge-draw/\",\n",
        "    \"https://stgeorgembc.com.au/christmas-buffet/\",\n",
        "    \"https://stgeorgembc.com.au/marina-extension/\",\n",
        "    \"https://stgeorgembc.com.au/new-marina-bonds/\",\n",
        "    \"https://stgeorgembc.com.au/instant-membership/\",\n",
        "    \"https://stgeorgembc.com.au/hire-me-today/\",\n",
        "    \"https://stgeorgembc.com.au/cocktail-hour/\",\n",
        "    \"https://stgeorgembc.com.au/virtualtour/\",\n",
        "    \"https://stgeorgembc.com.au/railway-pde-kogarah-clubhouse/\",\n",
        "    \"https://stgeorgembc.com.au/club-renovations-2022/\",\n",
        "    \"https://stgeorgembc.com.au/?page_id=328\",\n",
        "    \"https://stgeorgembc.com.au/?page_id=468\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =======================================================\n",
        "# 3. REQUEST FUNCTION WITH RETRIES & ERROR HANDLING\n",
        "# =======================================================\n",
        "def get_raw_html(url, api_key, max_retries=3, retry_delay=3):\n",
        "    \"\"\"\n",
        "    Sends a Firecrawl scrape request and returns raw HTML.\n",
        "    Retries up to max_retries times if the request fails.\n",
        "    \"\"\"\n",
        "    api_url = \"https://api.firecrawl.dev/v1/scrape\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"url\": url,\n",
        "        \"formats\": [\"rawHtml\"]\n",
        "    }\n",
        "\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "            # Successful request\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                if \"rawHtml\" in data:\n",
        "                    return data[\"rawHtml\"]\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Attempt {attempt}: 'rawHtml' missing in response.\")\n",
        "            else:\n",
        "                print(f\"‚ùå Attempt {attempt}: HTTP {response.status_code} for {url}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ùå Attempt {attempt}: Request error ‚Üí {e}\")\n",
        "\n",
        "        # Retry if not last attempt\n",
        "        if attempt < max_retries:\n",
        "            print(f\"üîÅ Retrying in {retry_delay} seconds...\")\n",
        "            time.sleep(retry_delay)\n",
        "\n",
        "    print(f\"‚õî Failed after {max_retries} attempts ‚Üí {url}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4. FETCH + SAVE HTML FILES\n",
        "# ================================\n",
        "os.makedirs(\"html_raw\", exist_ok=True)\n",
        "\n",
        "for i, url in enumerate(URLS):\n",
        "    api_key = FIRECRAWL_KEYS[i % len(FIRECRAWL_KEYS)]  # rotate API key\n",
        "\n",
        "    print(f\"\\n=== Fetching ({i+1}/{len(URLS)}) ‚Üí {url} ===\")\n",
        "    print(f\"Using API key: {api_key[:10]}...\")\n",
        "\n",
        "    html_content = get_raw_html(url, api_key)\n",
        "\n",
        "    if html_content:\n",
        "        filename = f\"html_raw/page_{i+1}.html\"\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(html_content)\n",
        "        print(f\"‚úî Saved: {filename}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Skipped saving due to repeated errors: {url}\")\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 5. ZIP HTML FILES\n",
        "# ======================\n",
        "zip_filename = \"html-raw.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, \"w\") as zipf:\n",
        "    for file in os.listdir(\"html_raw\"):\n",
        "        filepath = os.path.join(\"html_raw\", file)\n",
        "        zipf.write(filepath, arcname=file)\n",
        "\n",
        "print(\"\\n‚úî All HTML files zipped into:\", zip_filename)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 6. DOWNLOAD ZIP FILE\n",
        "# =========================\n",
        "files.download(zip_filename)\n",
        "print(\"‚¨áÔ∏è Download should begin automatically.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "othIAjTtDX1Y",
        "outputId": "4ac5ea03-ddcb-4e80-b647-7fbb777a5bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fetching (1/44) ‚Üí https://stgeorgembc.com.au/ ===\n",
            "Using API key: fc-8574178...\n",
            "‚ùå Attempt 1: HTTP 408 for https://stgeorgembc.com.au/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 2: HTTP 408 for https://stgeorgembc.com.au/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 3: HTTP 408 for https://stgeorgembc.com.au/\n",
            "‚õî Failed after 3 attempts ‚Üí https://stgeorgembc.com.au/\n",
            "‚ùå Skipped saving due to repeated errors: https://stgeorgembc.com.au/\n",
            "\n",
            "=== Fetching (2/44) ‚Üí https://stgeorgembc.com.au/about-us/ ===\n",
            "Using API key: fc-9d7d39e...\n",
            "‚ùå Attempt 1: HTTP 402 for https://stgeorgembc.com.au/about-us/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 2: HTTP 402 for https://stgeorgembc.com.au/about-us/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 3: HTTP 402 for https://stgeorgembc.com.au/about-us/\n",
            "‚õî Failed after 3 attempts ‚Üí https://stgeorgembc.com.au/about-us/\n",
            "‚ùå Skipped saving due to repeated errors: https://stgeorgembc.com.au/about-us/\n",
            "\n",
            "=== Fetching (3/44) ‚Üí https://stgeorgembc.com.au/clubgrants-2022/ ===\n",
            "Using API key: fc-7a24a77...\n",
            "‚ùå Attempt 1: HTTP 408 for https://stgeorgembc.com.au/clubgrants-2022/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 2: HTTP 408 for https://stgeorgembc.com.au/clubgrants-2022/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 3: HTTP 408 for https://stgeorgembc.com.au/clubgrants-2022/\n",
            "‚õî Failed after 3 attempts ‚Üí https://stgeorgembc.com.au/clubgrants-2022/\n",
            "‚ùå Skipped saving due to repeated errors: https://stgeorgembc.com.au/clubgrants-2022/\n",
            "\n",
            "=== Fetching (4/44) ‚Üí https://stgeorgembc.com.au/club-history/ ===\n",
            "Using API key: fc-c6e182f...\n",
            "‚ùå Attempt 1: HTTP 402 for https://stgeorgembc.com.au/club-history/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 2: HTTP 402 for https://stgeorgembc.com.au/club-history/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 3: HTTP 402 for https://stgeorgembc.com.au/club-history/\n",
            "‚õî Failed after 3 attempts ‚Üí https://stgeorgembc.com.au/club-history/\n",
            "‚ùå Skipped saving due to repeated errors: https://stgeorgembc.com.au/club-history/\n",
            "\n",
            "=== Fetching (5/44) ‚Üí https://stgeorgembc.com.au/trading-hours/ ===\n",
            "Using API key: fc-0f6b183...\n",
            "‚ùå Attempt 1: HTTP 408 for https://stgeorgembc.com.au/trading-hours/\n",
            "üîÅ Retrying in 3 seconds...\n",
            "‚ùå Attempt 2: HTTP 408 for https://stgeorgembc.com.au/trading-hours/\n",
            "üîÅ Retrying in 3 seconds...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install trafilatura\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from bs4 import BeautifulSoup\n",
        "from trafilatura import extract\n",
        "from google.colab import files\n",
        "\n",
        "# ====================================================\n",
        "# 1. UNRAR html-raws.rar ‚Üí html-raws/ folder\n",
        "# ====================================================\n",
        "\n",
        "# rar_path = \"/content/drive/MyDrive/Upwork/serv.rar\"\n",
        "extract_folder = \"/content/html-raws/serv\"\n",
        "\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "# Extract using unrar command\n",
        "#!unrar x -y rar_path html-raws/\n",
        "\n",
        "print(\"‚úî Extracted RAR into:\", extract_folder)\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 2. READ & PARSE HTML FILES WITH TRAFILATURA\n",
        "# ====================================================\n",
        "\n",
        "output_folder = \"text-files\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "text_file_paths = []\n",
        "\n",
        "for filename in os.listdir(extract_folder):\n",
        "    if not filename.lower().endswith(\".html\"):\n",
        "        continue\n",
        "\n",
        "    html_path = os.path.join(extract_folder, filename)\n",
        "\n",
        "    with open(html_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        html_content = f.read()\n",
        "\n",
        "    # ------------------------------------------------\n",
        "    # Extract <title>\n",
        "    # ------------------------------------------------\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    title_tag = soup.find(\"title\")\n",
        "\n",
        "    title = title_tag.text.strip() if title_tag else \"untitled\"\n",
        "\n",
        "    # Clean title for filenames\n",
        "    safe_title = (\n",
        "        title.replace(\"/\", \"_\")\n",
        "             .replace(\"\\\\\", \"_\")\n",
        "             .replace(\":\", \"_\")\n",
        "             .replace(\"*\", \"_\")\n",
        "             .replace(\"?\", \"_\")\n",
        "             .replace('\"', \"_\")\n",
        "             .replace(\"<\", \"_\")\n",
        "             .replace(\">\", \"_\")\n",
        "             .replace(\"|\", \"_\")\n",
        "             .strip()\n",
        "    )\n",
        "\n",
        "    # ------------------------------------------------\n",
        "    # Extract readable text using TRAFILATURA\n",
        "    # ------------------------------------------------\n",
        "    try:\n",
        "        text_content = extract(html_content)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Extraction error on {filename}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if not text_content:\n",
        "        print(f\"‚ö†Ô∏è No main content found in {filename}, skipping...\")\n",
        "        continue\n",
        "\n",
        "    # ------------------------------------------------\n",
        "    # Save to text file\n",
        "    # ------------------------------------------------\n",
        "    text_filename = f\"{safe_title}.txt\"\n",
        "    text_path = os.path.join(output_folder, text_filename)\n",
        "\n",
        "    with open(text_path, \"w\", encoding=\"utf-8\") as t:\n",
        "        t.write(text_content)\n",
        "\n",
        "    text_file_paths.append(text_path)\n",
        "\n",
        "    print(f\"‚úî Extracted ‚Üí {text_filename}\")\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# 3. COMBINE ALL TXT FILES INTO ONE MASTER FILE\n",
        "# ==========================================================\n",
        "\n",
        "combined_path = \"combined.txt\"\n",
        "\n",
        "with open(combined_path, \"w\", encoding=\"utf-8\") as combined:\n",
        "    for text_file in text_file_paths:\n",
        "        title = os.path.basename(text_file).replace(\".txt\", \"\")\n",
        "        combined.write(\"\\n\\n==============================\\n\")\n",
        "        combined.write(f\"### {title}\\n\")\n",
        "        combined.write(\"==============================\\n\\n\")\n",
        "\n",
        "        with open(text_file, \"r\", encoding=\"utf-8\") as t:\n",
        "            combined.write(t.read())\n",
        "            combined.write(\"\\n\")\n",
        "\n",
        "print(\"‚úî Combined file created:\", combined_path)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# 4. ZIP ALL TEXT FILES\n",
        "# ==========================================================\n",
        "\n",
        "zip_output = \"text-files.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_output, \"w\") as zipf:\n",
        "    for file in os.listdir(output_folder):\n",
        "        filepath = os.path.join(output_folder, file)\n",
        "        zipf.write(filepath, arcname=file)\n",
        "\n",
        "    zipf.write(combined_path, arcname=\"combined.txt\")\n",
        "\n",
        "print(\"‚úî Zipped all text files into:\", zip_output)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# 5. DOWNLOAD ZIP\n",
        "# ==========================================================\n",
        "\n",
        "files.download(zip_output)\n",
        "print(\"‚¨áÔ∏è Download should start automatically.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tt_yALZ0DUHl",
        "outputId": "8b861048-d488-4b11-98ec-4bac4d584c00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trafilatura\n",
            "  Downloading trafilatura-2.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2025.10.5)\n",
            "Requirement already satisfied: charset_normalizer>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.4.4)\n",
            "Collecting courlan>=1.3.2 (from trafilatura)\n",
            "  Downloading courlan-1.3.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting htmldate>=1.9.2 (from trafilatura)\n",
            "  Downloading htmldate-1.9.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura)\n",
            "  Downloading justext-3.0.2-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (5.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2.5.0)\n",
            "Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
            "Collecting tld>=0.13 (from courlan>=1.3.2->trafilatura)\n",
            "  Downloading tld-0.13.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.9.2->trafilatura)\n",
            "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
            "Collecting lxml_html_clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura)\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.17.0)\n",
            "Downloading trafilatura-2.0.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading courlan-1.3.2-py3-none-any.whl (33 kB)\n",
            "Downloading htmldate-1.9.4-py3-none-any.whl (31 kB)\n",
            "Downloading justext-3.0.2-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tld-0.13.1-py2.py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tld, lxml_html_clean, dateparser, courlan, justext, htmldate, trafilatura\n",
            "Successfully installed courlan-1.3.2 dateparser-1.2.2 htmldate-1.9.4 justext-3.0.2 lxml_html_clean-0.4.3 tld-0.13.1 trafilatura-2.0.0\n",
            "‚úî Extracted RAR into: /content/html-raws/serv\n",
            "‚úî Extracted ‚Üí SPEED BOATING CLUB - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Entertainment - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Railway Pde -Kogarah Clubhouse - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Trading Hours - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Meet our Chef‚Äôs - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí About Us - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí We Care - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Mon, Tues, Wed Badge Draw $7,000 - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí St George Motor Boat Club - Waterfront Function Centre Packages - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Frequently Asked Questions - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Dress Regulations - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Our Videos - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Club Moorings - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Virtual Tour - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Cocktail Hour - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Frequently asked questions _OLGR - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí CRUISING CLUB - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Christmas Day Seafood & Carvery Buffet 2025 - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí ClubGRANTS 2025 - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Boat Ramp - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Boat Hire - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí BOWLS CLUB - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Contact Us - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Latest News - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Hire Me Today - St George Motor Boat Club.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.utils:lxml parsing failed: Document is empty\n",
            "ERROR:trafilatura.utils:lxml parser bytestring Document is empty\n",
            "ERROR:trafilatura.core:empty HTML tree: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Extracted ‚Üí The Waterfront Function Centre - Wedding Reception Venues Sydney - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Membership Renewal - St George Motor Boat Club.txt\n",
            "‚ö†Ô∏è No main content found in 54.html, skipping...\n",
            "‚úî Extracted ‚Üí New Marina Berths - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Instant Membership - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Club History - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Join Our Team - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Home - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Sub Clubs - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Marina - St George Motor Boat Club.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.utils:lxml parsing failed: Document is empty\n",
            "ERROR:trafilatura.utils:lxml parser bytestring Document is empty\n",
            "ERROR:trafilatura.core:empty HTML tree: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Extracted ‚Üí Restaurant - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí FISHING CLUB - St George Motor Boat Club.txt\n",
            "‚ö†Ô∏è No main content found in 55.html, skipping...\n",
            "‚úî Extracted ‚Üí Gallery - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Happy Hour - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí What's On - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Digital Magazine - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Marina Extension - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí New Badge Draw - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Venue Safety Plan - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Christmas Marina's Edge Restaurant - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Restaurant - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Club Renovations 2022 - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Members Free Raffle - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Meet our Team - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Marina Berthing - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Half Day Rigid Inflatable Vessel Hire  - The St George Motor Boat Club Reservations.txt\n",
            "‚úî Extracted ‚Üí MENS AND WOMENS GOLF CLUB - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Our 100 Year Video - St George Motor Boat Club.txt\n",
            "‚úî Extracted ‚Üí Entertainment - St George Motor Boat Club.txt\n",
            "‚úî Combined file created: combined.txt\n",
            "‚úî Zipped all text files into: text-files.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d7ef73f-b697-4a11-8439-21a55968e87e\", \"text-files.zip\", 106246)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Download should start automatically.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x -y \"/content/drive/MyDrive/Upwork/serv.rar\" html-raws/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFSrU5rmHjwl",
        "outputId": "8d6aeb30-399c-415b-9e24-ed8632f2dd53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/Upwork/serv.rar\n",
            "\n",
            "Creating    html-raws                                                 OK\n",
            "Creating    html-raws/serv                                            OK\n",
            "Extracting  html-raws/serv/1.html                                        \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/10.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/11.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/12.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/13.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/14.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/15.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/16.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/17.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/18.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/19.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/2.html                                        \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/20.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/21.html                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/22.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/23.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/24.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/25.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/26.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/27.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/28.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/29.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/3.html                                        \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/30.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/31.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/32.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/33.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/34.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/35.html                                       \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/36.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/37.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/38.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/39.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/4.html                                        \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/40.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/41.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/42.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/43.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/44.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/45.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/46.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/47.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/48.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/49.html                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/5.html                                        \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/50.html                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/51.html                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/52.html                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/53.html                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/54.html                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/55.html                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/59-Set-Menu.pdf                               \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/6.html                                        \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/69-Set-Menu.pdf                               \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/7.html                                        \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/75-Set-Menu.pdf                               \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/8.html                                        \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/85-Set-Menu.pdf                               \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/9.html                                        \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Annual-Report-2024.pdf                        \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/BayBreeze-Cafe-231017.pdf                     \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/BayBreeze-Cafe-231017_2.pdf                   \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Clean-Boaties-Fact-Sheet-2024-1.pdf           \b\b\b\b 25%\b\b\b\b 39%\b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Contractor-WHS-Site-Induction-2025.pdf        \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Dont-spread-marine-pests.pdf                  \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Edge-Menu-250304.pdf                          \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Marina-Final-230913.pdf                       \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Marina-Policy-Final-24.pdf                    \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/marine-pests-booklet.pdf                      \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Marine-pests-in-southern-nsw.pdf              \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Pizza-.pdf                                    \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/POLLUTION-INCIDENT-RESPONSE-MANAGEMENT-PLAN-2024-FINAL.pdf     \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Primefact-Biofouling-on-recreational-vessels.pdf     \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/RailwayPdeKogarah_DinnerSpecials-July-Update-724x1024.jpg     \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/RailwayPdeKogarah_DinnerSpecials-July_Social-1024x1024.jpg     \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/RailwayPdeKogarah_DinnerSpecials-June-Ribs_Draft-724x1024.jpg     \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/RailwayPdeKogarah_DinnerSpecials-June_steakDraft-724x1024.jpg     \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/RailwayPdeKogarah_DinnerSpecials-ParmiJune_Draft-724x1024.jpg     \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/RailwayPdeKogarah_LunchSpecials-June_Lunch-Draft2-724x1024.jpg     \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Senior-Breakfast-230829-1024x745.jpg          \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/STGMBC-FSOP-V2-2025.pdf                       \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/STGMBC-FSOP.pdf                               \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Trailer-Permit-Rules-2024.pdf                 \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Vessel-Refueling-Policy-and-Procedure.pdf     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  html-raws/serv/Xmas-Edge-Menu-251113.jpg                     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_path = \"combined2.txt\"\n",
        "\n",
        "with open(combined_path, \"w\", encoding=\"utf-8\") as combined:\n",
        "    for text_file in text_file_paths:\n",
        "        title = os.path.basename(text_file).replace(\".txt\", \"\")\n",
        "        combined.write(\"\\n\\n==============================\\n\")\n",
        "        combined.write(f\"### {title}\\n\")\n",
        "        combined.write(\"==============================\\n\\n\")\n",
        "\n",
        "        with open(text_file, \"r\", encoding=\"utf-8\") as t:\n",
        "            combined.write(t.read())\n",
        "            combined.write(\"\\n\")\n",
        "\n",
        "print(\"‚úî Combined file created:\", combined_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqzWhtdy2cB1",
        "outputId": "30d03d12-bbed-49fa-9c36-c6888c187a62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Combined file created: combined2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "7fcd385b",
        "outputId": "4f45dd2a-0234-48ae-b096-c9361a12a3a1"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "output_folder = \"text-files\"\n",
        "combined_path = \"combined_new.txt\"\n",
        "zip_output = \"text-files_new.zip\"\n",
        "\n",
        "text_file_paths = []\n",
        "for filename in os.listdir(output_folder):\n",
        "    if filename.lower().endswith(\".txt\"):\n",
        "        text_file_paths.append(os.path.join(output_folder, filename))\n",
        "\n",
        "# ==========================================================\n",
        "# 1. COMBINE ALL TXT FILES INTO ONE MASTER FILE\n",
        "# ==========================================================\n",
        "\n",
        "with open(combined_path, \"w\", encoding=\"utf-8\") as combined:\n",
        "    for text_file in text_file_paths:\n",
        "        title = os.path.basename(text_file).replace(\".txt\", \"\")\n",
        "        combined.write(\"\\n\\n==============================\\n\")\n",
        "        combined.write(f\"### {title}\\n\")\n",
        "        combined.write(\"==============================\\n\\n\")\n",
        "\n",
        "        with open(text_file, \"r\", encoding=\"utf-8\") as t:\n",
        "            combined.write(t.read())\n",
        "            combined.write(\"\\n\")\n",
        "\n",
        "print(\"‚úî Combined file created:\", combined_path)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# 2. ZIP ALL TEXT FILES\n",
        "# ==========================================================\n",
        "\n",
        "with zipfile.ZipFile(zip_output, \"w\") as zipf:\n",
        "    for file in os.listdir(output_folder):\n",
        "        filepath = os.path.join(output_folder, file)\n",
        "        zipf.write(filepath, arcname=file)\n",
        "\n",
        "    zipf.write(combined_path, arcname=os.path.basename(combined_path))\n",
        "\n",
        "print(\"‚úî Zipped all text files into:\", zip_output)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# 3. DOWNLOAD ZIP\n",
        "# ==========================================================\n",
        "\n",
        "files.download(zip_output)\n",
        "print(\"‚¨áÔ∏è Download should start automatically.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Combined file created: combined_new.txt\n",
            "‚úî Zipped all text files into: text-files_new.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_51586ce4-0169-4fde-a8d2-77d68dd5eb7a\", \"text-files_new.zip\", 327651)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è Download should start automatically.\n"
          ]
        }
      ]
    }
  ]
}